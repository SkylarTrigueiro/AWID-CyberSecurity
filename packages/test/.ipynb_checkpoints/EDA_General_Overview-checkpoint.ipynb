{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.display import HTML\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classification_model.processing.data_management import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_orig = load_dataset(file_name='AWID-CLS-R-Trn.csv')\n",
    "test_orig = load_dataset(file_name='AWID-CLS-R-Tst.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classification_model.processing.feat_eng_categ import one_hot_encoder\n",
    "ohe = one_hot_encoder(features='class')\n",
    "ohe.fit(train_orig)\n",
    "train = ohe.transform(train_orig)\n",
    "test = ohe.transform(test_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classification_model.processing.feat_eng_categ import discrete_to_categ, one_hot_encoder, categ_missing_encoder, rare_label_encoder, label_encoder\n",
    "from classification_model.processing.feat_eng_num import outlier_capping, ArbitraryNumberImputer\n",
    "from classification_model.processing.feat_creation import feature_creation\n",
    "from classification_model.processing.feat_selection import remove_constant, remove_quasi_constant, remove_duplicates, selected_drop_features\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "eda_pipe = Pipeline([\n",
    "                ('fc', feature_creation()),\n",
    "                ('d2c', discrete_to_categ()),\n",
    "                ('rce', rare_label_encoder(tol=0.001)),\n",
    "                ('cme', categ_missing_encoder()),\n",
    "               ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = eda_pipe.fit_transform(train_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = label_encoder()\n",
    "train_label = le.fit_transform(X=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc  = remove_constant()\n",
    "rqc = remove_quasi_constant() \n",
    "rd  = remove_duplicates()\n",
    "\n",
    "train_label = rc.fit_transform(train_label)\n",
    "train_label = rqc.fit_transform(train_label)\n",
    "train_label = rd.fit_transform(train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = [col for col in train.columns if col not in train_label.columns ]\n",
    "train.drop(columns_to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = one_hot_encoder(features='class')\n",
    "train = ohe.fit_transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frame.time_epoch</th>\n",
       "      <th>frame.time_delta</th>\n",
       "      <th>frame.time_relative</th>\n",
       "      <th>frame.len</th>\n",
       "      <th>radiotap.length</th>\n",
       "      <th>radiotap.mactime</th>\n",
       "      <th>radiotap.datarate</th>\n",
       "      <th>radiotap.channel.freq</th>\n",
       "      <th>radiotap.channel.type.cck</th>\n",
       "      <th>radiotap.dbm_antsignal</th>\n",
       "      <th>...</th>\n",
       "      <th>wlan.qos.tid</th>\n",
       "      <th>wlan.qos.eosp</th>\n",
       "      <th>wlan.qos.ack</th>\n",
       "      <th>wlan.qos.amsdupresent</th>\n",
       "      <th>wlan.qos.bit4</th>\n",
       "      <th>data.len</th>\n",
       "      <th>class_normal</th>\n",
       "      <th>class_injection</th>\n",
       "      <th>class_impersonation</th>\n",
       "      <th>class_flooding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024271</td>\n",
       "      <td>0.024271</td>\n",
       "      <td>185</td>\n",
       "      <td>26</td>\n",
       "      <td>2.101623e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2437.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-47.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Rare</td>\n",
       "      <td>Rare</td>\n",
       "      <td>Rare</td>\n",
       "      <td>Rare</td>\n",
       "      <td>Rare</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001631</td>\n",
       "      <td>0.001631</td>\n",
       "      <td>0.025902</td>\n",
       "      <td>185</td>\n",
       "      <td>26</td>\n",
       "      <td>2.101625e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2437.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-64.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Rare</td>\n",
       "      <td>Rare</td>\n",
       "      <td>Rare</td>\n",
       "      <td>Rare</td>\n",
       "      <td>Rare</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.056956</td>\n",
       "      <td>0.055325</td>\n",
       "      <td>0.081227</td>\n",
       "      <td>159</td>\n",
       "      <td>26</td>\n",
       "      <td>2.101680e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2437.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-32.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Rare</td>\n",
       "      <td>Rare</td>\n",
       "      <td>Rare</td>\n",
       "      <td>Rare</td>\n",
       "      <td>Rare</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.057371</td>\n",
       "      <td>0.000415</td>\n",
       "      <td>0.081642</td>\n",
       "      <td>54</td>\n",
       "      <td>26</td>\n",
       "      <td>2.101682e+09</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2437.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Rare</td>\n",
       "      <td>Rare</td>\n",
       "      <td>Rare</td>\n",
       "      <td>Rare</td>\n",
       "      <td>Rare</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.057376</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.081647</td>\n",
       "      <td>40</td>\n",
       "      <td>26</td>\n",
       "      <td>2.101682e+09</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2437.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-24.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Rare</td>\n",
       "      <td>Rare</td>\n",
       "      <td>Rare</td>\n",
       "      <td>Rare</td>\n",
       "      <td>Rare</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 96 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   frame.time_epoch  frame.time_delta  frame.time_relative  frame.len  \\\n",
       "0          0.000000          0.024271             0.024271        185   \n",
       "1          0.001631          0.001631             0.025902        185   \n",
       "2          0.056956          0.055325             0.081227        159   \n",
       "3          0.057371          0.000415             0.081642         54   \n",
       "4          0.057376          0.000005             0.081647         40   \n",
       "\n",
       "  radiotap.length  radiotap.mactime  radiotap.datarate  radiotap.channel.freq  \\\n",
       "0              26      2.101623e+09                1.0                 2437.0   \n",
       "1              26      2.101625e+09                1.0                 2437.0   \n",
       "2              26      2.101680e+09                1.0                 2437.0   \n",
       "3              26      2.101682e+09               48.0                 2437.0   \n",
       "4              26      2.101682e+09               24.0                 2437.0   \n",
       "\n",
       "  radiotap.channel.type.cck  radiotap.dbm_antsignal  ... wlan.qos.tid  \\\n",
       "0                         1                   -47.0  ...         Rare   \n",
       "1                         1                   -64.0  ...         Rare   \n",
       "2                         1                   -32.0  ...         Rare   \n",
       "3                         0                   -21.0  ...         Rare   \n",
       "4                         0                   -24.0  ...         Rare   \n",
       "\n",
       "  wlan.qos.eosp  wlan.qos.ack wlan.qos.amsdupresent wlan.qos.bit4 data.len  \\\n",
       "0          Rare          Rare                  Rare          Rare      NaN   \n",
       "1          Rare          Rare                  Rare          Rare      NaN   \n",
       "2          Rare          Rare                  Rare          Rare      NaN   \n",
       "3          Rare          Rare                  Rare          Rare      NaN   \n",
       "4          Rare          Rare                  Rare          Rare      NaN   \n",
       "\n",
       "  class_normal class_injection class_impersonation  class_flooding  \n",
       "0            1               0                   0               0  \n",
       "1            1               0                   0               0  \n",
       "2            1               0                   0               0  \n",
       "3            1               0                   0               0  \n",
       "4            1               0                   0               0  \n",
       "\n",
       "[5 rows x 96 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diagnostic_plots(df, variable):\n",
    "    # function takes a dataframe (df) and\n",
    "    # the variable of interest as arguments\n",
    "\n",
    "    # define figure size\n",
    "    plt.figure(figsize=(16, 4))\n",
    "\n",
    "    # histogram\n",
    "    plt.subplot(1, 3, 1)\n",
    "    sns.distplot(df[variable], bins=30)\n",
    "    plt.title('Histogram')\n",
    "\n",
    "    # Q-Q plot\n",
    "    plt.subplot(1, 3, 2)\n",
    "    stats.probplot(df[variable], dist=\"norm\", plot=plt)\n",
    "    plt.ylabel('Variable quantiles')\n",
    "\n",
    "    # boxplot\n",
    "    plt.subplot(1, 3, 3)\n",
    "    sns.boxplot(y=df[variable])\n",
    "    plt.title('Boxplot')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['classl_norma'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-ff06cd344617>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'classl_norma'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'class_injection'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'class_impersonation'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'class_flooding'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'classl_norma'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'class_injection'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'class_impersonation'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'class_flooding'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2804\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2805\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2806\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2807\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2808\u001b[0m         \u001b[1;31m# take() does not accept boolean indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[1;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1551\u001b[0m         self._validate_read_indexer(\n\u001b[1;32m-> 1552\u001b[1;33m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1553\u001b[0m         )\n\u001b[0;32m   1554\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[1;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1643\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"loc\"\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1644\u001b[0m                 \u001b[0mnot_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1645\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{not_found} not in index\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1646\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1647\u001b[0m             \u001b[1;31m# we skip the warning on Categorical/Interval\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['classl_norma'] not in index\""
     ]
    }
   ],
   "source": [
    "y = train[['classl_normal', 'class_injection', 'class_impersonation', 'class_flooding']]\n",
    "train.drop(['classl_normal', 'class_injection', 'class_impersonation', 'class_flooding'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classification_model.processing.data_management import partition_features\n",
    "NUMERIC, NUMERIC_NA, CATEG, CATEG_NA, DISCRETE, DISCRETE_NA = partition_features(train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Numeric variables ####\n",
    "for feat in NUMERIC:\n",
    "    print( 'Feature:',feat)\n",
    "    print('')\n",
    "    print(train[feat].describe())\n",
    "    print(' ')\n",
    "    diagnostic_plots(train, feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feat in CATEG:\n",
    "    print( 'Feature:',feat)\n",
    "    print('')\n",
    "    print('Number of unique values:')\n",
    "    print(train[feat].nunique())\n",
    "    print('')\n",
    "    print('Value distribution:')\n",
    "    print((train[feat].value_counts().head(20)))\n",
    "    print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def h(content):\n",
    "    display(HTML(content))\n",
    "    \n",
    "def timehist(df, tcol, target, col, target_first, clipping=9999999999999999, concat_df = False, odf = None):\n",
    "    if concat_df == True:\n",
    "        df = pd.concat([df, odf])\n",
    "        \n",
    "    title = target + ' Hist ' + col\n",
    "    if( target_first==True):\n",
    "        df[df[target] == 1].set_index(tcol)[col].clip(0, clipping).plot(style='.', figsize=(15, 3))\n",
    "        df[df[target] == 0].set_index(tcol)[col].clip(0, clipping).plot(style='.', figsize=(15, 3))\n",
    "        plt.title(title)\n",
    "        plt.show()\n",
    "    elif( target_first==False):\n",
    "        df[df[target] == 0].set_index(tcol)[col].clip(0, clipping).plot(style='.', title= title, figsize=(15, 3))\n",
    "        df[df[target] == 1].set_index(tcol)[col].clip(0, clipping).plot(style='.', title= title, figsize=(15, 3))\n",
    "        plt.title(title)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _desc(data, col, label):\n",
    "    d0 = data.describe().reset_index()\n",
    "    d0.columns = [col, label]\n",
    "    return d0.append({col:'unique values', label:data.unique().shape[0]}, ignore_index=True) \\\n",
    "             .append({col:'NaNs', label:data.isnull().sum()}, ignore_index=True) \\\n",
    "             .append({col:'NaNs share', label:np.round(data.isnull().sum() / data.shape[0], 4)}, ignore_index=True) \\\n",
    "\n",
    "def desc(df_train, col, target, include_test=False, df_test=None):\n",
    "    d0 = _desc(df_train[col], col, 'Train')\n",
    "    d1 = _desc(df_train.loc[df_train[target] == 1, col], col, 'Train normal')\n",
    "    d2 = _desc(df_train.loc[df_train[target] == 0, col], col, 'Train not normal')\n",
    "    if( include_test):\n",
    "        d3 = _desc(df_test[col], col, 'Test')\n",
    "        d4 = _desc(df_test.loc[df_test[target] == 1, col], col, 'Test normal')\n",
    "        d5 = _desc(df_test.loc[df_test[target] == 0, col], col, 'Test not normal')\n",
    "    if( include_test):\n",
    "        dd = d0.merge(d1).merge(d2).merge(d3).merge(d4).merge(d5)\n",
    "    else:\n",
    "        dd = d0.merge(d1).merge(d2)\n",
    "    display(dd)\n",
    "    \n",
    "    h('<b>Most popular values (NaN = -999):</b>')\n",
    "    N = 10\n",
    "    d0 = df_train[[target,col]].groupby(col)[target].agg(['size','mean','sum']).reset_index().sort_values('size', ascending=False).reset_index(drop=True)\n",
    "    d0 = d0.head(N)\n",
    "    d0 = d0.rename({'size':'Count in train (desc)','mean':'Mean target train','sum':'Sum target train'}, axis=1)\n",
    "    display(d0)\n",
    "        \n",
    "    d1 = df_test[[target,col]].groupby(col)[target].agg(['size','mean','sum']).reset_index().sort_values('size', ascending=False).reset_index(drop=True)\n",
    "    d1 = d1.head(N)\n",
    "    d1 = d1.rename({'size':'Count in test (desc)','mean':'Mean target test','sum':'Sum target test'}, axis=1)\n",
    "    display(d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist1(df,col):\n",
    "    plt.figure(figsize=(15, 3))\n",
    "    plt.hist(df[col], bins=70);\n",
    "    plt.title('Train histogram: ' + col);\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr1(df,col):\n",
    "    N = None #10000\n",
    "    num_vars = [f for f in train.columns if train[f].dtype != 'object']\n",
    "    trx = df.head(N) if N is not None else df.copy()\n",
    "    corrs = trx[num_vars].corrwith(trx[col]).reset_index().sort_values(0, ascending=False).reset_index(drop=True).rename({'index':'Column',0:'Correlation with ' + col}, axis=1)\n",
    "    h('<b>Most correlated values with ' + col + ':</b>')\n",
    "    trx = pd.concat([corrs.head(6), corrs.dropna().tail(5)])\n",
    "    def linkx(val):\n",
    "        return '<a href=\"#c_{}\">{}</a>'.format(val, val)\n",
    "    trx['Column'] = trx['Column'].apply(linkx)\n",
    "    h(trx.to_html(escape=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numeric(df_input, tcol_input, target_input, col_input, target_first_input, df_test, include_test):\n",
    "    timehist(df=df_input, tcol=tcol_input, target=target_input, col=col_input, target_first=target_first_input, odf=df_test, concat_df=include_test)\n",
    "    hist1(df_input,col_input)\n",
    "    desc(df_input, col_input, target_input, include_test, df_test)\n",
    "    corr1(df_input,col_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical(df, col, target, df_test, include_test):\n",
    "    desc(df, col, target, include_test, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc(df, tcol, target, col, target_first, df_test, include_test):\n",
    "    if col not in ['isFraud','TransactionDT']:\n",
    "        h('<h3 id=\"c_' + col + '\">' + col + '</h3>' + '<a style=\"font-size:11px\" href=\"#home\">(Jump to top)</a>')\n",
    "        categorical(df, col, target, df_test, include_test) if train[col].dtype == 'object' else numeric(df, tcol, target, col, target_first, df_test, include_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = list(train.columns)\n",
    "for x in ['frame.time_epoch', 'class_normal', 'class_injection', 'class_impersonation', 'class_flooding']:\n",
    "    columns.remove(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for col in columns:\n",
    "    proc(df=train, tcol='frame.time_epoch', target='class_normal', col=col, target_first=True, df_test=test, include_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def h(content):\n",
    "    display(HTML(content))\n",
    "    \n",
    "def timehist(df, tcol, target, col, target_first, clipping=9999999999999999, concat_df = False, odf = None):\n",
    "    if concat_df == True:\n",
    "        df = pd.concat([df, odf])\n",
    "        \n",
    "    title = target + ' Hist ' + col\n",
    "    if( target_first==True):\n",
    "        df[df[target] == 1].set_index(tcol)[col].clip(0, clipping).plot(style='.', figsize=(15, 3))\n",
    "        df[df[target] == 0].set_index(tcol)[col].clip(0, clipping).plot(style='.', figsize=(15, 3))\n",
    "        plt.title(title)\n",
    "        plt.show()\n",
    "    elif( target_first==False):\n",
    "        df[df[target] == 0].set_index(tcol)[col].clip(0, clipping).plot(style='.', title= title, figsize=(15, 3))\n",
    "        df[df[target] == 1].set_index(tcol)[col].clip(0, clipping).plot(style='.', title= title, figsize=(15, 3))\n",
    "        plt.title(title)\n",
    "        plt.show()\n",
    "\n",
    "def _desc(data, col, label):\n",
    "    d0 = data.describe().reset_index()\n",
    "    d0.columns = [col, label]\n",
    "    return d0.append({col:'unique values', label:data.unique().shape[0]}, ignore_index=True) \\\n",
    "             .append({col:'NaNs', label:data.isnull().sum()}, ignore_index=True) \\\n",
    "             .append({col:'NaNs share', label:np.round(data.isnull().sum() / data.shape[0], 4)}, ignore_index=True) \\\n",
    "\n",
    "def desc(df_train, col, target, include_test=False, df_test=None):\n",
    "    d0 = _desc(df_train[col], col, 'Train')\n",
    "    d1 = _desc(df_train.loc[df_train[target] == 1, col], col, 'Train normal')\n",
    "    d2 = _desc(df_train.loc[df_train[target] == 0, col], col, 'Train not normal')\n",
    "    if( include_test):\n",
    "        d3 = _desc(df_test[col], col, 'Test')\n",
    "        d4 = _desc(df_test.loc[df_test[target] == 1, col], col, 'Test normal')\n",
    "        d5 = _desc(df_test.loc[df_test[target] == 0, col], col, 'Test not normal')\n",
    "    if( include_test):\n",
    "        dd = d0.merge(d1).merge(d2).merge(d3).merge(d4).merge(d5)\n",
    "    else:\n",
    "        dd = d0.merge(d1).merge(d2)\n",
    "    display(dd)\n",
    "    \n",
    "    h('<b>Most popular values (NaN = -999):</b>')\n",
    "    N = 10\n",
    "    d0 = df_train[[target,col]].groupby(col)[target].agg(['size','mean','sum']).reset_index().sort_values('size', ascending=False).reset_index(drop=True)\n",
    "    d0 = d0.head(N)\n",
    "    d0 = d0.rename({'size':'Count in train (desc)','mean':'Mean target train','sum':'Sum target train'}, axis=1)\n",
    "    display(d0)\n",
    "        \n",
    "    d1 = df_test[[target,col]].groupby(col)[target].agg(['size','mean','sum']).reset_index().sort_values('size', ascending=False).reset_index(drop=True)\n",
    "    d1 = d1.head(N)\n",
    "    d1 = d1.rename({'size':'Count in test (desc)','mean':'Mean target test','sum':'Sum target test'}, axis=1)\n",
    "    display(d1)\n",
    "\n",
    "def hist1(df,col):\n",
    "    plt.figure(figsize=(15, 3))\n",
    "    plt.hist(df[col], bins=70);\n",
    "    plt.title('Train histogram: ' + col);\n",
    "    plt.show()\n",
    "\n",
    "def corr1(df,col):\n",
    "    N = None #10000\n",
    "    num_vars = [f for f in train.columns if train[f].dtype != 'object']\n",
    "    trx = df.head(N) if N is not None else df.copy()\n",
    "    corrs = trx[num_vars].corrwith(trx[col]).reset_index().sort_values(0, ascending=False).reset_index(drop=True).rename({'index':'Column',0:'Correlation with ' + col}, axis=1)\n",
    "    h('<b>Most correlated values with ' + col + ':</b>')\n",
    "    trx = pd.concat([corrs.head(6), corrs.dropna().tail(5)])\n",
    "    def linkx(val):\n",
    "        return '<a href=\"#c_{}\">{}</a>'.format(val, val)\n",
    "    trx['Column'] = trx['Column'].apply(linkx)\n",
    "    h(trx.to_html(escape=False))\n",
    "\n",
    "def numeric(df_input, tcol_input, target_input, col_input, target_first_input, df_test, include_test):\n",
    "    timehist(df=df_input, tcol=tcol_input, target=target_input, col=col_input, target_first=target_first_input, odf=df_test, concat_df=include_test)\n",
    "    hist1(df_input,col_input)\n",
    "    desc(df_input, col_input, target_input, include_test, df_test)\n",
    "    corr1(df_input,col_input)\n",
    "\n",
    "def categorical(df, col, target, df_test, include_test):\n",
    "    desc(df, col, target, include_test, df_test)\n",
    "\n",
    "def proc(df, tcol, target, col, target_first, df_test, include_test):\n",
    "    if col not in ['isFraud','TransactionDT']:\n",
    "        h('<h3 id=\"c_' + col + '\">' + col + '</h3>' + '<a style=\"font-size:11px\" href=\"#home\">(Jump to top)</a>')\n",
    "        categorical(df, col, target, df_test, include_test) if train[col].dtype == 'object' else numeric(df, tcol, target, col, target_first, df_test, include_test)\n",
    "\n",
    "columns = list(train.columns)\n",
    "for x in ['frame.time_epoch', 'class_normal', 'class_injection', 'class_impersonation', 'class_flooding']:\n",
    "    columns.remove(x)\n",
    "\n",
    "for col in columns:\n",
    "    proc(df=train, tcol='frame.time_epoch', target='class_normal', col=col, target_first=True, df_test=test, include_test=True)def h(content):\n",
    "    display(HTML(content))\n",
    "    \n",
    "def timehist_normal(col):\n",
    "    N =  9999999999999999 # clip trans amount for better view\n",
    "    train[train['class_normal'] == 1].set_index('frame.time_epoch')[col].clip(0, N).plot(style='.', title='Hist ' + col, figsize=(15, 3))\n",
    "    train[train['class_normal'] == 0].set_index('frame.time_epoch')[col].clip(0, N).plot(style='.', title='Hist ' + col, figsize=(15, 3))\n",
    "    plt.title('class_normal')\n",
    "    plt.show()\n",
    "    \n",
    "def timehist_injection(col):\n",
    "    N =  9999999999999999 # clip trans amount for better view\n",
    "    train[train['class_injection'] == 0].set_index('frame.time_epoch')[col].clip(0, N).plot(style='.', title='Hist ' + col, figsize=(15, 3))\n",
    "    train[train['class_injection'] == 1].set_index('frame.time_epoch')[col].clip(0, N).plot(style='.', title='Hist ' + col, figsize=(15, 3))\n",
    "    plt.title('class_injection')\n",
    "    plt.show()\n",
    "    \n",
    "def timehist_impersonation(col):\n",
    "    N =  9999999999999999 # clip trans amount for better view\n",
    "    train[train['class_impersonation'] == 0].set_index('frame.time_epoch')[col].clip(0, N).plot(style='.', title='Hist ' + col, figsize=(15, 3))\n",
    "    train[train['class_impersonation'] == 1].set_index('frame.time_epoch')[col].clip(0, N).plot(style='.', title='Hist ' + col, figsize=(15, 3))\n",
    "    plt.title('class_impersonation')\n",
    "    plt.show()\n",
    "    \n",
    "def timehist_flooding(col):\n",
    "    N =  9999999999999999 # clip trans amount for better view\n",
    "    train[train['class_flooding'] == 0].set_index('frame.time_epoch')[col].clip(0, N).plot(style='.', title='Hist ' + col, figsize=(15, 3))\n",
    "    train[train['class_flooding'] == 1].set_index('frame.time_epoch')[col].clip(0, N).plot(style='.', title='Hist ' + col, figsize=(15, 3))\n",
    "    plt.title('class_flooding')\n",
    "    plt.show()\n",
    "\n",
    "def _desc(data, col, label):\n",
    "    d0 = data.describe().reset_index()\n",
    "    d0.columns = [col, label]\n",
    "    return d0.append({col:'unique values', label:data.unique().shape[0]}, ignore_index=True) \\\n",
    "             .append({col:'NaNs', label:data.isnull().sum()}, ignore_index=True) \\\n",
    "             .append({col:'NaNs share', label:np.round(data.isnull().sum() / data.shape[0], 4)}, ignore_index=True) \\\n",
    "\n",
    "def desc_normal(col):\n",
    "    d0 = _desc(train[col], col, 'Train')\n",
    "    d1 = _desc(train.loc[train['class_normal'] == 1, col], col, 'Train normal')\n",
    "    d2 = _desc(train.loc[train['class_normal'] == 0, col], col, 'Train not normal')\n",
    "    dd = d0.merge(d1).merge(d2)\n",
    "    display(dd)\n",
    "    \n",
    "    h('<b>Most popular values (NaN = -999):</b>')\n",
    "    N = 10\n",
    "    d0 = train[['class_normal',col]].fillna(-999).groupby(col)['class_normal'].agg(['size','mean','sum']).reset_index().sort_values('size', ascending=False).reset_index(drop=True)\n",
    "    dd = d0.head(N)\n",
    "    dd = dd.rename({'size':'Count in train (desc)','mean':'Mean normal target','sum':'Sum target','TransactionID':'Count in test'}, axis=1)\n",
    "    display(dd)\n",
    "\n",
    "    h('<b>Biggest normal sum values in train (NaN = -999):</b>')\n",
    "    dd = d0.sort_values('sum', ascending=False).reset_index(drop=True).head(N).merge(d1, how='left', on=col)\n",
    "    dd = dd.rename({'size':'Count in train','mean':'Mean target','sum':'Sum target (desc)','TransactionID':'Count in test'}, axis=1)\n",
    "    display(dd)\n",
    "    \n",
    "def desc_injection(col):\n",
    "    d0 = _desc(train[col], col, 'Train')\n",
    "    d1 = _desc(train.loc[train['class_injection'] == 1, col], col, 'Train injection')\n",
    "    d2 = _desc(train.loc[train['class_injection'] == 0, col], col, 'Train not injection')\n",
    "    dd = d0.merge(d1).merge(d2)\n",
    "    display(dd)\n",
    "    \n",
    "    h('<b>Most popular values (NaN = -999):</b>')\n",
    "    N = 10\n",
    "    d0 = train[['class_injection',col]].fillna(-999).groupby(col)['class_injection'].agg(['size','mean','sum']).reset_index().sort_values('size', ascending=False).reset_index(drop=True)\n",
    "    dd = d0.head(N)\n",
    "    dd = dd.rename({'size':'Count in train (desc)','mean':'Mean target','sum':'Sum target','TransactionID':'Count in test'}, axis=1)\n",
    "    display(dd)\n",
    "\n",
    "    h('<b>Biggest fraud sum values in train (NaN = -999):</b>')\n",
    "    dd = d0.sort_values('sum', ascending=False).reset_index(drop=True).head(N).merge(d1, how='left', on=col)\n",
    "    dd = dd.rename({'size':'Count in train','mean':'Mean target','sum':'Sum target (desc)','TransactionID':'Count in test'}, axis=1)\n",
    "    display(dd)\n",
    "    \n",
    "def desc_impersonation(col):\n",
    "    d0 = _desc(train[col], col, 'Train')\n",
    "    d1 = _desc(train.loc[train['class_impersonation'] == 1, col], col, 'Train impersonatin')\n",
    "    d2 = _desc(train.loc[train['class_impersonation'] == 0, col], col, 'Train not impersonation')\n",
    "    dd = d0.merge(d1).merge(d2)\n",
    "    display(dd)\n",
    "    \n",
    "    h('<b>Most popular values (NaN = -999):</b>')\n",
    "    N = 10\n",
    "    d0 = train[['class_impersonation',col]].fillna(-999).groupby(col)['class_impersonation'].agg(['size','mean','sum']).reset_index().sort_values('size', ascending=False).reset_index(drop=True)\n",
    "    dd = d0.head(N)\n",
    "    dd = dd.rename({'size':'Count in train (desc)','mean':'Mean target','sum':'Sum target','TransactionID':'Count in test'}, axis=1)\n",
    "    display(dd)\n",
    "\n",
    "    h('<b>Biggest fraud sum values in train (NaN = -999):</b>')\n",
    "    dd = d0.sort_values('sum', ascending=False).reset_index(drop=True).head(N).merge(d1, how='left', on=col)\n",
    "    dd = dd.rename({'size':'Count in train','mean':'Mean target','sum':'Sum target (desc)','TransactionID':'Count in test'}, axis=1)\n",
    "    display(dd)\n",
    "    \n",
    "def desc_flooding(col):\n",
    "    d0 = _desc(train[col], col, 'Train')\n",
    "    d1 = _desc(train.loc[train['class_flooding'] == 1, col], col, 'Train impersonatin')\n",
    "    d2 = _desc(train.loc[train['class_flooding'] == 0, col], col, 'Train not impersonation')\n",
    "    dd = d0.merge(d1).merge(d2)\n",
    "    display(dd)\n",
    "    \n",
    "    h('<b>Most popular values (NaN = -999):</b>')\n",
    "    N = 10\n",
    "    d0 = train[['class_flooding',col]].fillna(-999).groupby(col)['class_flooding'].agg(['size','mean','sum']).reset_index().sort_values('size', ascending=False).reset_index(drop=True)\n",
    "    dd = d0.head(N)\n",
    "    dd = dd.rename({'size':'Count in train (desc)','mean':'Mean target','sum':'Sum target','TransactionID':'Count in test'}, axis=1)\n",
    "    display(dd)\n",
    "\n",
    "    h('<b>Biggest fraud sum values in train (NaN = -999):</b>')\n",
    "    dd = d0.sort_values('sum', ascending=False).reset_index(drop=True).head(N).merge(d1, how='left', on=col)\n",
    "    dd = dd.rename({'size':'Count in train','mean':'Mean target','sum':'Sum target (desc)','TransactionID':'Count in test'}, axis=1)\n",
    "    display(dd)\n",
    "\n",
    "def hist1(col):\n",
    "    plt.figure(figsize=(15, 3))\n",
    "    plt.hist(train[col], bins=70);\n",
    "    plt.title('Train histogram: ' + col);\n",
    "    plt.show()\n",
    "\n",
    "def corr1(col):\n",
    "    N = None #10000\n",
    "    num_vars = [f for f in train.columns if train[f].dtype != 'object']\n",
    "    trx = train.head(N) if N is not None else tr.copy()\n",
    "    corrs = trx[num_vars].corrwith(trx[col]).reset_index().sort_values(0, ascending=False).reset_index(drop=True).rename({'index':'Column',0:'Correlation with ' + col}, axis=1)\n",
    "    h('<b>Most correlated values with ' + col + ':</b>')\n",
    "    trx = pd.concat([corrs.head(6), corrs.dropna().tail(5)])\n",
    "    def linkx(val):\n",
    "        return '<a href=\"#c_{}\">{}</a>'.format(val, val) if val in included_cols else val\n",
    "    trx['Column'] = trx['Column'].apply(linkx)\n",
    "    h(trx.to_html(escape=False))\n",
    "    \n",
    "def numeric(col):\n",
    "    timehist_normal(col)\n",
    "    timehist_injection(col)\n",
    "    timehist_impersonation(col)\n",
    "    timehist_flooding(col)\n",
    "    hist1(col)\n",
    "    desc_normal(col)\n",
    "    desc_injection(col)\n",
    "    desc_impersonation(col)\n",
    "    desc_flooding(col)\n",
    "    corr1(col)\n",
    "    \n",
    "def categorical(col):\n",
    "    desc_normal(col)\n",
    "    desc_injection(col)\n",
    "    desc_impersonation(col)\n",
    "    desc_flooding(col)\n",
    "    \n",
    "def proc(col):\n",
    "    if col not in ['isFraud','TransactionDT']:\n",
    "        h('<h3 id=\"c_' + col + '\">' + col + '</h3>' + '<a style=\"font-size:11px\" href=\"#home\">(Jump to top)</a>')\n",
    "        categorical(col) if train[col].dtype == 'object' else numeric(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = list(train.columns)\n",
    "drop_list = ['class_normal', 'class_injection', 'class_impersonation', 'class_flooding', 'frame.time_epoch' ]\n",
    "columns = [ val for val in columns if val not in drop_list ]\n",
    "for col in columns:\n",
    "    proc(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
