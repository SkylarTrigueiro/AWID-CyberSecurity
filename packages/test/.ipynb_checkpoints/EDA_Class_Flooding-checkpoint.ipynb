{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.display import HTML\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classification_model.processing.data_management import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_orig = load_dataset(file_name='AWID-CLS-R-Trn.csv')\n",
    "test_orig = load_dataset(file_name='AWID-CLS-R-Tst.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1795574 575642\n"
     ]
    }
   ],
   "source": [
    "print(len(train_orig), len(test_orig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classification_model.processing.data_management import get_target\n",
    "train_orig, y_train = get_target(train_orig)\n",
    "test_orig, y_test = get_target(test_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1795574 575642\n"
     ]
    }
   ],
   "source": [
    "print(len(train_orig), len(test_orig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classification_model.processing.feat_eng_categ import discrete_to_categ, one_hot_encoder, categ_missing_encoder, rare_label_encoder, label_encoder\n",
    "from classification_model.processing.feat_eng_num import outlier_capping, ArbitraryNumberImputer\n",
    "from classification_model.processing.feat_creation import feature_creation\n",
    "from classification_model.processing.feat_selection import remove_constant, remove_quasi_constant, remove_duplicates, selected_drop_features, remove_correlated_features\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classification_model.config import config\n",
    "\n",
    "eda_pipe = Pipeline([\n",
    "                ('cme1', categ_missing_encoder(config.ID_FEATURES)),\n",
    "                ('fc', feature_creation()),\n",
    "                ('oc', outlier_capping(distribution='quantiles')),\n",
    "                ('cme2', categ_missing_encoder()),\n",
    "                ('rle', rare_label_encoder(0.0001)),                \n",
    "                ('ani', ArbitraryNumberImputer()),\n",
    "                ('le', label_encoder()),\n",
    "                ('sd', selected_drop_features()),\n",
    "                ('rc', remove_constant()),\n",
    "                ('rqc', remove_quasi_constant()),\n",
    "                ('rcf', remove_correlated_features()), \n",
    "               ])\n",
    "\n",
    "eda_final_pipe = Pipeline([\n",
    "                ('cme1', categ_missing_encoder(config.ID_FEATURES)),\n",
    "                ('fc', feature_creation()),\n",
    "                ('oc', outlier_capping(distribution='quantiles')),\n",
    "                ('cme2', categ_missing_encoder()),\n",
    "                ('rle', rare_label_encoder(0.0001)),                \n",
    "                ('ani', ArbitraryNumberImputer()),\n",
    "                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_prep = eda_pipe.fit_transform(train_orig)\n",
    "test_prep = eda_pipe.transform(test_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train_prep.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "eda_pipe.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = [col for col in train_orig if col not in train_prep]\n",
    "train = eda_final_pipe.fit_transform(train_orig)\n",
    "test = eda_final_pipe.transform(test_orig)\n",
    "\n",
    "train.drop(columns_to_drop, axis=1, inplace=True)\n",
    "test.drop(columns_to_drop, axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['class'] = y_train\n",
    "test['class'] = y_test\n",
    "\n",
    "train['frame.time_epoch'] = train_orig['frame.time_epoch']\n",
    "test['frame.time_epoch'] = test_orig['frame.time_epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( len(train), len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classification_model.processing.feat_eng_categ import one_hot_encoder\n",
    "ohe = one_hot_encoder(features='class')\n",
    "train = ohe.fit_transform(train)\n",
    "test = ohe.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def h(content):\n",
    "    display(HTML(content))\n",
    "    \n",
    "def timehist(df, tcol, target, col, target_first, clipping=9999999999999999, concat_df = False, odf = None):\n",
    "    if concat_df == True:\n",
    "        df = pd.concat([df, odf])\n",
    "        \n",
    "    title = target + ' Hist ' + col\n",
    "    if( target_first==True):\n",
    "        df[df[target] == 1].set_index(tcol)[col].clip(0, clipping).plot(style='.', figsize=(15, 3))\n",
    "        df[df[target] == 0].set_index(tcol)[col].clip(0, clipping).plot(style='.', figsize=(15, 3))\n",
    "        plt.title(title)\n",
    "        plt.show()\n",
    "    elif( target_first==False):\n",
    "        df[df[target] == 0].set_index(tcol)[col].clip(0, clipping).plot(style='.', title= title, figsize=(15, 3))\n",
    "        df[df[target] == 1].set_index(tcol)[col].clip(0, clipping).plot(style='.', title= title, figsize=(15, 3))\n",
    "        plt.title(title)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _desc(data, col, label):\n",
    "    d0 = data.describe().reset_index()\n",
    "    d0.columns = [col, label]\n",
    "    return d0.append({col:'unique values', label:data.unique().shape[0]}, ignore_index=True) \\\n",
    "             .append({col:'NaNs', label:data.isnull().sum()}, ignore_index=True) \\\n",
    "             .append({col:'NaNs share', label:np.round(data.isnull().sum() / data.shape[0], 4)}, ignore_index=True) \\\n",
    "\n",
    "def desc(df_train, col, target, include_test=False, df_test=None):\n",
    "    d0 = _desc(df_train[col], col, 'Train')\n",
    "    d1 = _desc(df_train.loc[df_train[target] == 1, col], col, 'Train flooding')\n",
    "    d2 = _desc(df_train.loc[df_train[target] == 0, col], col, 'Train not flooding')\n",
    "    if( include_test):\n",
    "        d3 = _desc(df_test[col], col, 'Test')\n",
    "        d4 = _desc(df_test.loc[df_test[target] == 1, col], col, 'Test flooding')\n",
    "        d5 = _desc(df_test.loc[df_test[target] == 0, col], col, 'Test not flooding')\n",
    "    if( include_test):\n",
    "        dd = d0.merge(d1).merge(d2).merge(d3).merge(d4).merge(d5)\n",
    "    else:\n",
    "        dd = d0.merge(d1).merge(d2)\n",
    "    display(dd)\n",
    "    \n",
    "    h('<b>Most popular values (NaN = -999):</b>')\n",
    "    N = 10\n",
    "    d0 = df_train[[target,col]].groupby(col)[target].agg(['size','mean','sum']).reset_index().sort_values('size', ascending=False).reset_index(drop=True)\n",
    "    d0 = d0.head(N)\n",
    "    d0 = d0.rename({'size':'Count in train (desc)','mean':'Mean target train','sum':'Sum target train'}, axis=1)\n",
    "    display(d0)\n",
    "        \n",
    "    d1 = df_test[[target,col]].groupby(col)[target].agg(['size','mean','sum']).reset_index().sort_values('size', ascending=False).reset_index(drop=True)\n",
    "    d1 = d1.head(N)\n",
    "    d1 = d1.rename({'size':'Count in test (desc)','mean':'Mean target test','sum':'Sum target test'}, axis=1)\n",
    "    display(d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist1(df,col):\n",
    "    plt.figure(figsize=(15, 3))\n",
    "    plt.hist(df[col], bins=70);\n",
    "    plt.title('Train histogram: ' + col);\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr1(df,col):\n",
    "    N = None #10000\n",
    "    num_vars = [f for f in df.columns if train[f].dtype != 'object']\n",
    "    trx = df.head(N) if N is not None else df.copy()\n",
    "    corrs = trx[num_vars].corrwith(trx[col]).reset_index().sort_values(0, ascending=False).reset_index(drop=True).rename({'index':'Column',0:'Correlation with ' + col}, axis=1)\n",
    "    h('<b>Most correlated values with ' + col + ':</b>')\n",
    "    trx = pd.concat([corrs.head(6), corrs.dropna().tail(5)])\n",
    "    def linkx(val):\n",
    "        return '<a href=\"#c_{}\">{}</a>'.format(val, val)\n",
    "    trx['Column'] = trx['Column'].apply(linkx)\n",
    "    h(trx.to_html(escape=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numeric(df_input, tcol_input, target_input, col_input, target_first_input, df_test, include_test):\n",
    "    timehist(df=df_input, tcol=tcol_input, target=target_input, col=col_input, target_first=target_first_input, odf=df_test, concat_df=include_test)\n",
    "    hist1(df_input,col_input)\n",
    "    desc(df_input, col_input, target_input, include_test, df_test)\n",
    "    corr1(df_input,col_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical(df, col, target, df_test, include_test):\n",
    "    desc(df, col, target, include_test, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc(df, tcol, target, col, target_first, df_test, include_test):\n",
    "    if col not in ['isFraud','TransactionDT']:\n",
    "        h('<h3 id=\"c_' + col + '\">' + col + '</h3>' + '<a style=\"font-size:11px\" href=\"#home\">(Jump to top)</a>')\n",
    "        categorical(df, col, target, df_test, include_test) if train[col].dtype == 'object' else numeric(df, tcol, target, col, target_first, df_test, include_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = list(train.columns)\n",
    "for x in ['class_normal', 'class_injection', 'class_impersonation', 'class_flooding', 'frame.time_epoch', 'passed1second']:\n",
    "    print(x)\n",
    "    columns.remove(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for col in columns:\n",
    "    proc(df=train, tcol='frame.time_epoch', target='class_flooding', col=col, target_first=False, df_test=test, include_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
